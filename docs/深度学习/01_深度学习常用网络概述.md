---
sidebar_position: 1
---

# 深度学习常用网络概述

## 1.1 概述

**深度学习**（英语：deep learning）是机器学习的分支，是一种以人工神经网络为架构，对资料进行表征学习的算法。深度学习中的形容词“深度”是指在网络中使用多层。 早期的工作表明，线性感知器不能成为通用分类器，但具有非多项式激活函数和一个无限宽度隐藏层的网络可以成为通用分类器。

深度学习是机器学习中一种基于对数据进行表征学习的算法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。

表征学习的目标是寻求更好的表示方法并建立更好的模型来从大规模未标记数据中学习这些表示方法。表示方法来自神经科学，并松散地建立在类似神经系统中的信息处理和对通信模式的理解上，如神经编码，试图定义拉动神经元的反应之间的关系以及大脑中的神经元的电活动之间的关系。

至今已有数种深度学习框架，如深度神经网络、卷积神经网络和深度置信网络和循环神经网络已被应用在计算机视觉、语音识别、自然语言处理、音频识别与生物信息学等领域并获取了极好的效果。

另外，“深度学习”已成为时髦术语，或者说是人工神经网络的品牌重塑。

## 1.2 卷积神经网络（CNN）

卷积神经网络（Convolutional Neural Network, CNN）是一种专门用于处理网格结构数据（如图像）的深度学习模型。CNN 主要通过局部连接和权重共享来减少计算复杂度，同时利用卷积操作提取数据的空间特征。

更多内容👉：[卷积神经网络（CNN）基础](./卷积神经网络/02_卷积神经网络（CNN）基础.md)

### 1.2.1 AlexNet

AlexNet 是 2012 年 ILSVRC（ImageNet Large Scale Visual Recognition Challenge）竞赛中获胜的深度卷积神经网络，由 Alex Krizhevsky 等人提出。AlexNet 通过更深的网络结构、ReLU 激活函数和 Dropout 技术，在图像分类任务上取得了突破性的成果。

更多内容👉：[AlexNet详解](./卷积神经网络/03_AlexNet详解.md)

### 1.2.2 VGG Net

VGG Net 是由牛津大学视觉几何组（Visual Geometry Group, VGG）在 2014 年提出的一种深度卷积神经网络。该网络通过使用多个 3×3 的小卷积核叠加，增加了网络深度，同时保持计算效率和参数控制。

更多内容👉：[VGG Net详解](./卷积神经网络/04_VGG%20Net详解.md)

### 1.2.3 GoogleNet

GoogleNet（Inception V1）是由 Google 研究团队在 2014 年提出的深度卷积神经网络，并在 ILSVRC 2014 竞赛中取得冠军。其核心思想是 Inception 模块，通过不同尺度的卷积核并行提取特征，提升了计算效率并降低了参数量。

更多内容👉：[GoogleNet详解](./卷积神经网络/05_GoogleNet详解.md)

### 1.2.4 ResNet

ResNet（Residual Network）是由微软研究院的 Kaiming He 等人于 2015 年提出的深度卷积神经网络，旨在解决深度神经网络中的梯度消失和训练困难问题。ResNet 引入了残差学习的概念，即通过引入跳跃连接（skip connection）来构建残差模块，允许信息直接流过网络，避免梯度消失和信息损失。

ResNet 在多个计算机视觉任务中取得了显著的成果，包括图像分类、目标检测等。ResNet 通过引入跳跃连接极大地缓解了深层网络训练过程中的梯度消失问题，因此成为深度神经网络中非常重要的一类架构。

更多内容👉：[ResNet详解](./卷积神经网络/06.ResNet详解.md)